# Verdict Configuration
# Update these values for your Azure Databricks environment

# Unity Catalog
catalog:
  name: verdict
  schemas:
    raw: raw
    evaluated: evaluated
    metrics: metrics

# Azure Databricks Authentication
# Supports: azure_ad (recommended), managed_identity, pat
azure:
  # Authentication method: "azure_ad", "managed_identity", or "pat"
  auth_method: "azure_ad"
  # Azure AD app registration (for azure_ad method)
  tenant_id: "${AZURE_TENANT_ID}"
  client_id: "${AZURE_CLIENT_ID}"
  client_secret: "${AZURE_CLIENT_SECRET}"
  # Azure Key Vault for secrets (optional)
  key_vault_name: "${AZURE_KEY_VAULT_NAME}"
  # Workspace URL (e.g., https://adb-<workspace-id>.<random>.azuredatabricks.net)
  workspace_url: "${DATABRICKS_HOST}"

# Model Endpoints
endpoints:
  # Model endpoint to evaluate (update with your endpoint name)
  model: "databricks-gpt-oss-20b"
  # Judge model for LLM-as-a-judge evaluation
  judge: "databricks-llama-4-maverick"

# MLflow
mlflow:
  experiment_path: "/verdict/experiments"

# Regression Detection
regression:
  # Threshold for flagging regression (percentage drop)
  threshold_pct: 5.0
  # Statistical significance level
  p_value_threshold: 0.05
  # Metrics to track for regression
  metrics:
    - faithfulness
    - answer_relevance
    - judge_score
    - rouge_l
    - latency_p95

# Alerts
alerts:
  # Webhook URL for notifications (use dbutils.secrets for sensitive values)
  webhook_url_secret: "verdict/alerts_webhook"
  # Email recipients (comma-separated)
  email_recipients_secret: "verdict/alert_emails"
  # Alert on these verdict labels
  on_labels:
    - WARN
    - FAIL

# Evaluation
evaluation:
  # Sample size for evaluation (null = all)
  sample_size: null
  # Batch size for parallel evaluation
  batch_size: 100

# RAG Test Dataset Generator
testgen:
  qdrant:
    url: "${QDRANT_URL}"
    collection: "${QDRANT_COLLECTION}"
    text_field: "text"
    scroll_limit: 200
  azure_openai:
    endpoint: "${AZURE_OPENAI_ENDPOINT}"
    deployment: "gpt-4o"
    api_version: "2024-02-01"
  generation:
    samples_per_chunk: 1
    hard_negatives_per_query: 2
    delay_between_calls: 0.5
  output_dir: "./output"