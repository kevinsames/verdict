{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Initialize Unity Catalog",
    "\n\nCreates the verdict catalog, schemas, and Delta tables"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport os\n\n# Add src/verdict to path for imports when running from git repo\n# In Databricks with git_source, notebooks run from /Workspace/.../notebooks/\n# We need to go up one level to reach the repo root containing src/\nnotebook_dir = os.getcwd()\nrepo_root = os.path.dirname(notebook_dir)  # Go up from notebooks/ to repo root\nsrc_path = os.path.join(repo_root, \"src\")\n\nif src_path not in sys.path:\n    sys.path.insert(0, src_path)\n    \nprint(f\"Notebook dir: {notebook_dir}\")\nprint(f\"Repo root: {repo_root}\")\nprint(f\"Added to sys.path: {src_path}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import logging\nfrom verdict.setup.init_catalog import VerdictCatalogSetup\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbutils.widgets.text(\"catalog_name\", \"verdict\")",
    "# catalog_name = dbutils.widgets.get(\"catalog_name\")",
    "catalog_name = \"verdict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Initializing Unity Catalog: {catalog_name}\")",
    "",
    "setup = VerdictCatalogSetup(catalog_name=catalog_name)",
    "setup.run_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Unity Catalog setup complete!\")",
    "",
    "# Verify tables exist",
    "spark.sql(f\"SHOW TABLES IN {catalog_name}.raw\").display()",
    "spark.sql(f\"SHOW TABLES IN {catalog_name}.evaluated\").display()",
    "spark.sql(f\"SHOW TABLES IN {catalog_name}.metrics\").display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+json": {
   "runAs": "OWNER",
   "dashboards": []
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}